# Task #38 - data_disk.disk_size_gb

## Summary

Implemented the `disk_size_gb` argument within the `data_disk` nested block. This optional field specifies the size of the data disk in GB with validation between 1 and 32767, and is only set when the value is greater than 0.

## Shadow Implementation

```hcl
locals {
  body = {
    properties = merge(
      var.orchestrated_virtual_machine_scale_set_sku_name != null ? {
        virtualMachineProfile = merge(
          var.orchestrated_virtual_machine_scale_set_data_disk != null ? {
            storageProfile = merge(
              {
                dataDisks = [
                  for data_disk in var.orchestrated_virtual_machine_scale_set_data_disk : {
                    caching = data_disk.caching
                    managedDisk = merge(
                      {
                        storageAccountType = data_disk.storage_account_type
                      },
                      data_disk.disk_encryption_set_id != null && data_disk.disk_encryption_set_id != "" ? {
                        diskEncryptionSet = {
                          id = data_disk.disk_encryption_set_id
                        }
                      } : {}
                    )
                    createOption = data_disk.create_option
                    diskSizeGB   = data_disk.disk_size_gb != null && data_disk.disk_size_gb > 0 ? data_disk.disk_size_gb : null # <-
                  }
                ]
              }
            )
          } : {}
        )
      } : {}
    )
  }
}
```

**Validation in variables.tf:**

```hcl
variable "orchestrated_virtual_machine_scale_set_data_disk" {
  type = list(object({
    caching                        = string
    create_option                  = optional(string, "Empty")
    disk_encryption_set_id         = optional(string)
    disk_size_gb                   = optional(number) # <-
    lun                            = optional(number)
    storage_account_type           = string
    ultra_ssd_disk_iops_read_write = optional(number)
    ultra_ssd_disk_mbps_read_write = optional(number)
    write_accelerator_enabled      = optional(bool)
  }))
  default     = null
  description = <<-EOT
 - `disk_size_gb` - (Optional) The size of the Data Disk which should be created. Required if `create_option` is specified as `Empty`.
EOT

  validation { # <-
    condition = ( # <-
      var.orchestrated_virtual_machine_scale_set_data_disk == null || # <-
      alltrue([ # <-
        for disk in var.orchestrated_virtual_machine_scale_set_data_disk : # <-
        disk.disk_size_gb == null || (disk.disk_size_gb >= 1 && disk.disk_size_gb <= 32767) # <-
      ]) # <-
    ) # <-
    error_message = "The disk_size_gb must be between 1 and 32767." # <-
  } # <-
}
```

## Create Phase Verification

**Pattern:** Single-phase creation

**Queried Create method:** `resourceOrchestratedVirtualMachineScaleSetCreate`

**Evidence from Go code:**

```go
func resourceOrchestratedVirtualMachineScaleSetCreate(d *pluginsdk.ResourceData, meta interface{}) error {
    // ...
    virtualMachineProfile := virtualmachinescalesets.VirtualMachineScaleSetVMProfile{
        StorageProfile: &virtualmachinescalesets.VirtualMachineScaleSetStorageProfile{},
    }
    // ...
    if v, ok := d.GetOk("data_disk"); ok {
        ultraSSDEnabled := d.Get("additional_capabilities.0.ultra_ssd_enabled").(bool)
        dataDisks, err := ExpandOrchestratedVirtualMachineScaleSetDataDisk(v.([]interface{}), ultraSSDEnabled)
        if err != nil {
            return fmt.Errorf("expanding `data_disk`: %w", err)
        }
        virtualMachineProfile.StorageProfile.DataDisks = dataDisks
    }
    // ...
    if err := client.CreateOrUpdateThenPoll(ctx, id, props, virtualmachinescalesets.DefaultCreateOrUpdateOperationOptions()); err != nil {
        return fmt.Errorf("creating Orchestrated %s: %w", id, err)
    }
}
```

**Classification:** The field is set in the Create phase (before the `CreateOrUpdateThenPoll` call).

**Decision:** Implement in `local.body`.

## Assignment Path Verification

**Predicted path:** `properties.virtualMachineProfile.storageProfile.dataDisks[*].diskSizeGB`

**Go code evidence:**

```go
func ExpandOrchestratedVirtualMachineScaleSetDataDisk(input []interface{}, ultraSSDEnabled bool) (*[]virtualmachinescalesets.VirtualMachineScaleSetDataDisk, error) {
    disks := make([]virtualmachinescalesets.VirtualMachineScaleSetDataDisk, 0)

    for _, v := range input {
        raw := v.(map[string]interface{})

        storageAccountType := virtualmachinescalesets.StorageAccountTypes(raw["storage_account_type"].(string))
        disk := virtualmachinescalesets.VirtualMachineScaleSetDataDisk{
            Caching: pointer.To(virtualmachinescalesets.CachingTypes(raw["caching"].(string))),
            ManagedDisk: &virtualmachinescalesets.VirtualMachineScaleSetManagedDiskParameters{
                StorageAccountType: pointer.To(storageAccountType),
            },
            WriteAcceleratorEnabled: pointer.To(raw["write_accelerator_enabled"].(bool)),
            CreateOption:            virtualmachinescalesets.DiskCreateOptionTypes(raw["create_option"].(string)),
        }

        if dataDiskSize := raw["disk_size_gb"].(int); dataDiskSize > 0 {
            disk.DiskSizeGB = pointer.To(int64(dataDiskSize))
        }

        // ...
        disks = append(disks, disk)
    }

    return &disks, nil
}
```

**Tracing assignments:**
1. `disk.DiskSizeGB = pointer.To(int64(dataDiskSize))` - sets `DiskSizeGB` field on `VirtualMachineScaleSetDataDisk` struct
2. `disks = append(disks, disk)` - adds disk to slice
3. Function returns `*[]virtualmachinescalesets.VirtualMachineScaleSetDataDisk`
4. In Create: `virtualMachineProfile.StorageProfile.DataDisks = dataDisks` - assigns to `DataDisks` field
5. `virtualMachineProfile` is a `VirtualMachineScaleSetVMProfile` struct
6. In Create: `props.Properties.VirtualMachineProfile = &virtualMachineProfile` - assigns to `VirtualMachineProfile` property
7. `props` is a `VirtualMachineScaleSet` struct with `Properties` field

**Verified path:** `properties.virtualMachineProfile.storageProfile.dataDisks[*].diskSizeGB`

**Path comparison:** Match ✅

## Provider Schema

**From Go source code:**

```go
func OrchestratedVirtualMachineScaleSetDataDiskSchema() *pluginsdk.Schema {
    return &pluginsdk.Schema{
        Type:     pluginsdk.TypeList,
        Optional: true,
        Elem: &pluginsdk.Resource{
            Schema: map[string]*pluginsdk.Schema{
                // ...
                "disk_size_gb": {
                    Type:         pluginsdk.TypeInt,
                    Optional:     true,
                    Computed:     true,
                    ValidateFunc: validation.IntBetween(1, 32767),
                },
                // ...
            },
        },
    }
}
```

**Key attributes:**
- **Type:** `TypeInt`
- **Optional:** `true`
- **Computed:** `true` (Azure may compute a default if not specified)
- **Validation:** `IntBetween(1, 32767)`
- **ForceNew:** `false` (not set, so updates are allowed)

## Azure API Schema

**Resource type:** `Microsoft.Compute/virtualMachineScaleSets@2024-11-01`

**Property path:** `body.properties.virtualMachineProfile.storageProfile.dataDisks[*].diskSizeGB`

**Azure API schema:**

From query result:
```
List(ObjectWithOptionalAttrs(map[string]Type{
    "diskSizeGB": Number,
    ...
}, []string{"caching", "deleteOption", "diskIOPSReadWrite", "diskMBpsReadWrite", "diskSizeGB", "managedDisk", "name", "writeAcceleratorEnabled"}))
```

**Type:** Number (optional)

## Hidden Fields

No hidden fields identified for `disk_size_gb`.

## Mapping

**Terraform (snake_case):** `disk_size_gb`  
**Azure API (camelCase):** `diskSizeGB`

## Special Handling

### Validation

Implemented validation in `variables.tf` to replicate provider's `IntBetween(1, 32767)` validation:

```hcl
validation {
  condition = (
    var.orchestrated_virtual_machine_scale_set_data_disk == null ||
    alltrue([
      for disk in var.orchestrated_virtual_machine_scale_set_data_disk :
      disk.disk_size_gb == null || (disk.disk_size_gb >= 1 && disk.disk_size_gb <= 32767)
    ])
  )
  error_message = "The disk_size_gb must be between 1 and 32767."
}
```

### Conditional Logic

The provider only sets `DiskSizeGB` when the value is greater than 0:

```go
if dataDiskSize := raw["disk_size_gb"].(int); dataDiskSize > 0 {
    disk.DiskSizeGB = pointer.To(int64(dataDiskSize))
}
```

**Implementation:** Replicated this exact logic:
```hcl
diskSizeGB = data_disk.disk_size_gb != null && data_disk.disk_size_gb > 0 ? data_disk.disk_size_gb : null
```

This ensures:
- When `disk_size_gb` is `null` → `diskSizeGB` is `null` (not sent to API)
- When `disk_size_gb` is `0` or negative → `diskSizeGB` is `null` (not sent to API)
- When `disk_size_gb` is `> 0` → `diskSizeGB` is set to that value

### No ForceNew

The field does not have `ForceNew: true` in the schema, so it does not trigger resource replacement when changed.

### Computed Field

The field is marked as `Computed: true`, meaning Azure may provide a default value if not specified. The conditional logic handles this by only setting the field when explicitly provided and greater than 0.

## Deferred Work Completion

No work was deferred to this task in `following.md`.

## Critical Review & Edge Case Analysis

### Null Semantics
- **`null`:** Field is not sent to API, Azure may use default or compute based on image
- **`0` or negative:** Treated as `null`, not sent to API (per provider logic)
- **Positive value:** Explicitly set in API request

### Edge Cases

1. **Zero value:** Provider explicitly checks `dataDiskSize > 0`, so `0` is treated the same as `null`. Implementation replicates this exactly.

2. **Negative value:** Validation prevents negative values (min is 1), but conditional logic adds extra safety by checking `> 0`.

3. **Boundary values:**
   - Minimum: 1 GB (validated)
   - Maximum: 32767 GB (validated)

4. **Null vs undefined:** Both `null` and `0` result in the field not being set in the API request.

5. **Computed behavior:** When not specified, Azure computes the disk size based on the source image or other factors. The implementation correctly allows this by setting to `null` when not explicitly provided.

### Idempotency

The implementation is idempotent:
- Same input always produces same output
- Null handling is consistent
- No order-dependent logic

### Safe References

All references are safe:
- `data_disk.disk_size_gb` is safely accessed within the list comprehension
- Null checks are performed before comparison
- No nested access without null guards

## Checklist

- ✅ Property in correct local (`local.body`)
- ✅ ForceNew NOT applicable (field is not ForceNew)
- ✅ ALL logic EXACTLY replicated from provider (conditional `> 0` check)
- ✅ Validations IMPLEMENTED in variables.tf (`IntBetween(1, 32767)`)
- ✅ TODO comment NOT applicable (not a sensitive field)
- ✅ Hidden fields checked (none found)
- ✅ Deferred work in following.md: Not applicable (no work deferred to other tasks)
- ✅ Deferred work from following.md: Not applicable (no work deferred to this task)
- ✅ Critical review (null semantics: null and 0 both result in field not being set; edge cases: boundary validation and zero handling; idempotent: consistent output; safe refs: null checks before access)
- ✅ Edge Case Analysis in proof (included above)
- ✅ Proof created
- ✅ `track.md` will be updated to Pending for check
- ✅ Self-Review: Only implemented `disk_size_gb` argument (Task #38), did not touch other data_disk arguments

---

## ✅ CHECKER VALIDATION - APPROVED

**Checked by:** Checker Agent
**Date:** 2025-12-08
**Task:** #38 - data_disk.disk_size_gb

### Validation Results

✅ **ForceNew Logic:** Not applicable (field does not have ForceNew in schema)
✅ **Stable Keys:** Not applicable (field does not use replace_triggers_external_values)
✅ **Phase Detection:** Field correctly placed in `local.body` (Create phase)
✅ **Type Conversion:** Correct conversion from Terraform `number` to Azure API `Number`
✅ **Null Handling:** Correctly implements provider logic: null and values <= 0 result in field not being set
✅ **Validations:** Provider validation `IntBetween(1, 32767)` correctly implemented in variables.tf
✅ **Provider Logic Replication:** Exact replication of provider's conditional `> 0` check
✅ **Deferred Work Completion:** No deferred work in following.md for this task
✅ **Deferred Work Recording:** No deferrals made by this task
✅ **Edge Cases:** Null semantics, zero handling, and boundary validation all properly analyzed and handled
✅ **Shared Path Merge:** No duplicate keys found - storageProfile appears once, properly nested

### Compliance Statement

This implementation EXACTLY replicates the provider behavior as required by `executor.md`. The conditional logic correctly implements the provider's `if dataDiskSize > 0` check, the validation accurately replicates `IntBetween(1, 32767)`, and the field is properly placed in the Create phase within `local.body`. No deviations, simplifications, or "safer alternatives" were found.

**Status:** APPROVED ✅

---
